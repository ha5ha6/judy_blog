---
layout: single
title: Notes
permalink: "/notes/"
author_profile: true
#breadcrumbs: true

header:
  overlay_image: /assets/images/tutorial.jpg
  #actions:
  #  - label: "Download"
  #    url: "https://github.com/mmistakes/minimal-mistakes/"
  #caption: "Photo credit: J.Wang"
#excerpt: "an affordable and sustainable robot colony platform based on Android"
author:  Jiexin Wang
#classes:  wide
#toc: true
#toc_label: "Index"
usemathjax: true
---

## Reinforcement Learning

[Basic Reinforcement Learning](/judy_blog/basicrl/): MDP, value functions, policy/value iteration, Monte Carlo control, on/off policy, off policy importance sampling, and their python realizations with examples as follows

[\[Overview\]](https://github.com/ha5ha6/judy_tutorial_basicRL) [\[Gridworld, Blackjack\]](https://github.com/ha5ha6/judy_tutorial_basicRL/blob/main/girdworld_blackjack.ipynb)

[Temporal-Difference Learning](/judy_blog/td/): TD(0), SARSA, Q-learning, Expected SARSA, Double Q-learning and their python realizations with examples as follows

[\[Random Walk\]](https://github.com/ha5ha6/judy_tutorial_basicRL/blob/main/random_walk.ipynb) [\[Windy Grid\]](https://github.com/ha5ha6/judy_tutorial_basicRL/blob/main/windy_grid.ipynb) [\[Cliff Walking\]](https://github.com/ha5ha6/judy_tutorial_basicRL/blob/main/cliff_walking.ipynb) [\[Max Bias\]](https://github.com/ha5ha6/judy_tutorial_basicRL/blob/main/max_bias.ipynb)

Policy Gradient and Actor-Critic: TBD

[All About Cartpole](/judy_blog/cartpole/): Cartpole realizations with classic RL algorithms: Q-learning, SARSA($$\lambda$$), DQN, etc

## Deep Learning

## Others
